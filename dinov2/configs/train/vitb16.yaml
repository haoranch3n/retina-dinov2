train:
  batch_size_per_gpu: 64
  dataset_path: Fundus
student:
  arch: vit_base
  patch_size: 16
  drop_path_rate: 0.2
  ffn_layer: mlp
  block_chunks: 4
optim:
  epochs: 500
  weight_decay_end: 0.2
  base_lr: 5.0e-04  # learning rate for a batch size of 1024
  warmup_epochs: 80
  layerwise_decay: 1.0